{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocessing.ipynb","provenance":[],"authorship_tag":"ABX9TyMTKA9bOqG7dn6ZMb4eXoPq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Nfk76WYViP41"},"source":["# First, import revelant packages to assist in data extraction and formatting in Python.\n","import pandas as pd\n","import numpy as np\n","import os\n","import datetime\n","import glob\n","from pathlib import Path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lzEAmDBUibxi"},"source":["# Our team downloaded the 27 CSV files which contained survey responses from April 2020 to March 2021. After downloading these files into a folder, we \n","# parsed through them and combined them into a single dataframe in Python. \n","\n","# First, we ensured that all of the correct CSVs were in the specified folder, by listing all the CSV file in the directory. Actual directory path removed to maintain anonymity.\n","path = r''\n","for filename in glob.glob(path):\n","    data = pd.read_csv(filename)\n","    df = pd.DataFrame(data)\n","    print(filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghthG0pIleCA"},"source":["# After verifying that all the correct files were in our destination folder, we proceeded to combine all of the CSVs into one Pandas Dataframe.\n","\n","# Specify Path in which you have saved the Census CSV files. Actual path name removed to maintain anonymity.\n","path = r''\n","\n","# Combine CSVs into one dataframe.\n","df = pd.concat([pd.read_csv(f, encoding='latin1') for f in glob.glob(path)],ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zn9ILr2WmFfC"},"source":["# After saving the data into a single Pandas dataframe, we exported the data into one large CSV file & Parquet file so that our team members could download and use in Python and Tableau.\n","df.to_csv('Full Dataset2.csv', index=False, mode = 'a')\n","\n","# Dataframe was saved to Parquet in our shared Google Drive. Actual Google Drive link removed to maintain anonymity.\n","df.to_parquet('')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3iUMttD6m4DG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618893301695,"user_tz":240,"elapsed":159,"user":{"displayName":"Niaoniao Ma","photoUrl":"","userId":"15369324244233398216"}},"outputId":"53fd33c0-8781-439f-8485-543b98b6d942"},"source":["# After saving our Combined Dataframe into a CSV file, our team placed that folder in our Google Drive, and mounted our Drive to Colab, so that all members of the team\n","# could access the file. Mounting the Drive allows our team to connect to & import files that are stored in our shared Google Drive. \n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4xIO4ojnTZUI"},"source":["# After mounting the Drive, our team read the Parquet file which contained data for all survey weeks into Colab. \n","data = pd.read_parquet('/content/drive/Shareddrives/GCP-UCDavis/data/full_dataset.parquet')\n","\n","# We were now ready to move onto the Data Preprocessing stage."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WWk-BS_KnLq2"},"source":["# Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"PTK51G5MwUwB"},"source":["# First, while the survey starting and ending date was known to our team, it was listed in the raw data as only a week number, and was not correctly formatted for analysis in Tableau.\n","# Our team edited this so that correct dates were listed and the correct formatting was used.\n","\n","# Give each week the starting day's date. \n","two_weeks = datetime.timedelta(days=14)\n","week = datetime.timedelta(days=7)\n","\n","# Get dates for 1st phase of surveys (every week starting 4/23)\n","week1 = datetime.datetime(2020, 4, 23)\n","phase1 = []\n","for i in range(0,13):\n","  phase1.append(str(week1.date()))\n","  week1 = week1 + week\n","\n","# Get dates for 2nd phase of surveys (every two weeks starting 8/19)\n","week13 = datetime.datetime(2020, 8, 19)\n","phase2 = []\n","for i in range(0,16):\n","  phase2.append(str(week13.date()))\n","  week13 = week13 + two_weeks\n","\n","weeks_date = phase1 + phase2\n","weeks_date.remove('2020-12-09')\n","weeks_date.remove('2020-04-30')\n","weeks_num = [i for i in range(1,28)]\n","\n","# Save the 'DATE' variable back into the Dataframe with the changes that we have made.\n","data['DATE'] = data.WEEK"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DzXE3PdglZGC"},"source":["# Next, our team focused in on the Vaccination variable in the dataset. As we were concerned with both vaccine sentiment and those who had already received a vaccine,\n","# we found a dynamic way to combine the variable that determined whether or not someone had received the vaccine with their vaccine sentiment.\n","\n","# In the data, people were only asked about their sentiment on the vaccine (whether or not they would take the vaccine) if they had indicated that they had NOT already been vaccinated.\n","# Vaccinated indivduals were already vaccinated, and so their sentiments on the vaccine were already known.\n","\n","# We combined these two variables into a single variable 'VACC', where the input was '9' if the individual was already vaccinated, and returned their sentiments on the vaccine otherwise.\n","data['VACC'] = np.where(data.RECVDVACC == 1, 9, data.GETVACC)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AVfKuPb-oe9X"},"source":["# Next, certain survey responses were not ideal for EDA. For many variables, a number was listed that determined an individual's response, rather than their actual response. These \n","# numbers were not always intuitive and often had multiple levels, making it necessary for our team to transform responses into text that we could interpret. This would allow our team\n","# to more easily discern relationships, and in performing EDA. \n","\n","variables = [{\n","  \"col_name\": \"DATE\",\n","  \"answers\": weeks_date,\n","  \"values\": weeks_num\n","}, {\n","  \"col_name\": \"VACC\",\n","  \"answers\": [\"Definitely\", \"Probably\", \"Probably NOT\", \"Definitely NOT\", \"Vaccinated\", np.nan, np.nan],\n","  \"values\": [ 1, 2, 3, 4, 9, -99, -88]\n","}, {\n","  \"col_name\": \"HADCOVID\",\n","  \"answers\": ['Yes', 'No', 'Not Sure', np.nan, np.nan],\n","  \"values\": [1,2,3,-99,-88]\n","}, {\n","  \"col_name\": \"WRKLOSS\",\n","  \"answers\":  ['Yes', 'No', np.nan, np.nan],\n","  \"values\": [1,2,-99,-88]\n","}, {\n","  \"col_name\": \"KINDWORK\",\n","  \"answers\": [\"Government\", \"Private Company\", \"Non Profit Organization\", 'Self-Employed', 'Working in a Family Business', np.nan, np.nan],\n","  \"values\": [1, 2, 3,4,5,-99,-88]\n","}, {\n","  \"col_name\": \"TW_START\",\n","  \"answers\": [\"Yes\", \"No\", \"No Change\", np.nan, np.nan],\n","  \"values\": [1, 2, 3,-99,-88]\n","}, {\n","  \"col_name\": \"EXPNS_DIF\",\n","  \"answers\": [\"Not at all Difficult\", \"A little difficult\", \"Somewhat Difficult\", 'Very Difficult', np.nan, np.nan],\n","  \"values\": [1, 2, 3,4,-99,-88]\n","}, {\n","  \"col_name\": \"PLNDTRIPS\",\n","  \"answers\": [\"Yes\", \"No\", np.nan, np.nan],\n","  \"values\": [1, 2, -99,-88]\n","}, {\n","  \"col_name\": \"ANXIOUS\",\n","  \"answers\": [\"Not at all\", \"Several Days\", \"More than Half the Days\", 'Nearly Every Day', np.nan, np.nan],\n","  \"values\": [1, 2, 3, 4, -99, -88]\n","}, {\n","  \"col_name\": \"WORRY\",\n","  \"answers\": [\"Not at all\", \"Several Days\", \"More than Half the Days\", 'Nearly Every Day', np.nan, np.nan],\n","  \"values\": [1, 2, 3, 4, -99, -88]\n","}, {\n","  \"col_name\": \"INTEREST\",\n","  \"answers\": [\"Not at all\", \"Several Days\", \"More than Half the Days\", 'Nearly Every Day', np.nan, np.nan],\n","  \"values\": [1, 2, 3, 4, -99, -88]\n","}, {\n","  \"col_name\": \"DOWN\",\n","  \"answers\": [\"Not at all\", \"Several Days\", \"More than Half the Days\", 'Nearly Every Day', np.nan, np.nan],\n","  \"values\": [1, 2, 3, 4, -99, -88]\n","}, {\n","  \"col_name\": \"PRESCRIPT\",\n","  \"answers\": [\"Yes\", \"No\", np.nan, np.nan],\n","  \"values\": [1, 2, -99,-88]\n","}, {\n","  \"col_name\": \"MH_SVCS\",\n","  \"answers\": [\"Yes\", \"No\", np.nan, np.nan],\n","  \"values\": [1, 2, -99,-88]\n","}, {\n","  \"col_name\": \"MH_NOTGET\",\n","  \"answers\": [\"Yes\", \"No\", np.nan, np.nan],\n","  \"values\": [1, 2, -99,-88]   \n","},{\n","  \"col_name\": \"INCOME\",\n","  \"answers\": ['Less than $25,000', '$25,000-$49,999', '$25,000-$49,999', '$50,000-74,999', '$75,000-$99,000','$100,000-$149,999',\n","            '$150,000 and above','$150,000 and above', np.nan, np.nan],\n","  \"values\": [1, 2, 3, 4, 5, 6, 7, 8, -99, -88]\n","}, {\n","  \"col_name\": \"EST_ST\",\n","  \"answers\":  [\n","    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n","    'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois',\n","    'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts',\n","    'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n","    'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio',\n","    'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee',\n","    'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming'],\n","  \"values\": [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n","            24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n","            42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56]\n","}, {\n","  \"col_name\": \"PRIVHLTH\",\n","  \"answers\": [\"yes\", \"no\", np.nan],\n","  \"values\": [1, 2, 3]\n","}, {\n","  \"col_name\": \"PUBHLTH\",\n","  \"answers\": [\"yes\", \"no\", np.nan],\n","  \"values\": [1, 2, 3]\n","}, {\n","  \"col_name\": \"REGION\",\n","  \"answers\": [\"Northeast\", \"South\", \"Midwest\", \"West\"],\n","  \"values\": [1, 2, 3, 4]\n","}]\n","\n","# Next, our team defined a conditional response that ensured that the index and arrow choices were arrays of the same length. This would prevent \n","# our transformations from changing rows in the Dataframe.\n","def categorize(col, indexes, choices):\n","  if len(indexes) != len(choices):\n","    return print('indexes and choices must be arrays of same length')\n","   \n","  conditions = [data[col] == index for index in indexes]\n","  return np.select(conditions, choices, default=np.nan)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ig4KdB-en_f"},"source":["# For our listed variables, replace the values with the answers that we had indicated.\n","for i in variables:\n","  data[i['col_name']] = categorize(i['col_name'], i['values'], i['answers'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DbEiCNGVHuSL"},"source":["# Certain data responses were easier to change using the Pandas .loc function. This function finds all values within a specified column, and replaces them with\n","# values that our team has indicated.\n","\n","# While birth year was listed in the dataset, our team found that analysis and relationships were easier to determine after breaking apart respondent age into age brackets.\n","# Using the respondent's birth year, we separated respondents into age brackets.\n","data['AGE_GROUP'] = \"\"\n","data.loc[(data.TBIRTH_YEAR >= 1996),'AGE_GROUP'] = \"18 - 24\"\n","data.loc[(data.TBIRTH_YEAR >= 1981) & (data.TBIRTH_YEAR <= 1995),'AGE_GROUP'] = \"25 - 39\"\n","data.loc[(data.TBIRTH_YEAR >= 1966) & (data.TBIRTH_YEAR <= 1980),'AGE_GROUP'] = \"40 - 54\"\n","data.loc[(data.TBIRTH_YEAR >= 1956) & (data.TBIRTH_YEAR <= 1965),'AGE_GROUP'] = \"55 - 64\"\n","data.loc[(data.TBIRTH_YEAR <= 1955),'AGE_GROUP'] = \"65 and above\"\n","\n","# Our team transformed gender responses from 1 & 2 to Male and Female respectively.\n","data['GENDER'] = \"\"\n","data.loc[(data.EGENDER == 2),'GENDER'] = \"Female\"\n","data.loc[(data.EGENDER == 1),'GENDER'] = \"Male\"\n","\n","# There were two variables that determined ethnicity in our dataset - one question prompted whether or not survey respondents were Hispanic, and another asked for their ethnicity.\n","# Our team combined these two variables into a single 'RACE_ETHNICITY' variable to analyze difference in vaccine sentiment between different indicated ethnicities.\n","data['RACE_ETHNICITY'] = \"\"\n","data.loc[data.RHISPANIC == 2,'RACE_ETHNICITY'] = \"Hispanic\"\n","data.loc[(data.RHISPANIC == 1) & (data.RRACE == 1),'RACE_ETHNICITY'] = \"White alone\"\n","data.loc[(data.RHISPANIC == 1) & (data.RRACE == 2),'RACE_ETHNICITY'] = \"Black alone\"\n","data.loc[(data.RHISPANIC == 1) & (data.RRACE == 3),'RACE_ETHNICITY'] = \"Asian alone\"\n","data.loc[(data.RHISPANIC == 1) & (data.RRACE == 4),'RACE_ETHNICITY'] = \"Other races\"\n","\n","# Our team similarly transformed survey responses on Education level to text that we could use in analysis.\n","data['EDUCATION'] = \"\"\n","data.loc[(data.EEDUC >= 1) & (data.EEDUC <= 2),'EDUCATION'] = \"Less than a high school diploma\"\n","data.loc[(data.EEDUC == 3) ,'EDUCATION'] = \"High school diploma or GED\"\n","data.loc[(data.EEDUC >= 4) & (data.EEDUC <= 5),'EDUCATION'] = \"Some college/associate's degree\"\n","data.loc[(data.EEDUC >= 6) & (data.EEDUC <= 7),'EDUCATION'] = \"Bachelor's degree or higher\"\n","\n","# Our team similarly transformed survey responses on Marital Status to divide survey respondents into 'Married' and 'Not Married' subgroups.\n","data['MARITAL_STATUS'] =\"\"\n","data.loc[(data.MS == 1),'MARITAL_STATUS'] = \"Married\"\n","data.loc[(data.MS != 1),'MARITAL_STATUS'] = \"Others\"\n","\n","# Our team extracted data on household size and added to our Pandas Dataframe.\n","data['HOUSEHOLD_SIZE'] = data['THHLD_NUMPER']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pHl-i87ZKwte"},"source":["# Next, the data provided 16 different reasons for which one was unlikely to take the vaccine. For each of these responses, our team transformed the responses to '1' indicating a 'Yes' \n","# response to that question, and a '0' if the response was anything other than 1. This allowed our team to compare the reasons listed for not taking the vaccine.\n","\n","data['YN1'] = \"\"\n","data.loc[(data.WHYNOT1 == 1), 'YN1'] = 1\n","data.loc[(data.WHYNOT1 != 1),'YN1'] = 0\n","\n","data['YN2'] = \"\"\n","data.loc[(data.WHYNOT2 == 1), 'YN2'] = 1\n","data.loc[(data.WHYNOT2 != 1),'YN2'] = 0\n","\n","data['YN3'] = \"\"\n","data.loc[(data.WHYNOT3 == 1), 'YN3'] = 1\n","data.loc[(data.WHYNOT3 != 1),'YN3'] = 0\n","\n","data['YN4'] = \"\"\n","data.loc[(data.WHYNOT4 == 1), 'YN4'] = 1\n","data.loc[(data.WHYNOT4 != 1),'YN4'] = 0\n","\n","data['YN5'] = \"\"\n","data.loc[(data.WHYNOT5 == 1), 'YN5'] = 1\n","data.loc[(data.WHYNOT5 != 1),'YN5'] = 0\n","\n","data['YN6'] = \"\"\n","data.loc[(data.WHYNOT6 == 1), 'YN6'] = 1\n","data.loc[(data.WHYNOT6 != 1),'YN6'] = 0\n","\n","data['YN7'] = \"\"\n","data.loc[(data.WHYNOT7 == 1), 'YN7'] = 1\n","data.loc[(data.WHYNOT7 != 1),'YN7'] = 0\n","\n","data['YN8'] = \"\"\n","data.loc[(data.WHYNOT8 == 1), 'YN8'] = 1\n","data.loc[(data.WHYNOT8 != 1),'YN8'] = 0\n","\n","data['YN9'] = \"\"\n","data.loc[(data.WHYNOT9 == 1), 'YN9'] = 1\n","data.loc[(data.WHYNOT9 != 1),'YN9'] = 0\n","\n","data['YN10'] = \"\"\n","data.loc[(data.WHYNOT10 == 1), 'YN10'] = 1\n","data.loc[(data.WHYNOT10 != 1),'YN10'] = 0\n","\n","data['YN11'] = \"\"\n","data.loc[(data.WHYNOT11 == 1), 'YN11'] = 1\n","data.loc[(data.WHYNOT11 != 1),'YN11'] = 0\n","\n","data['YNB1'] = \"\"\n","data.loc[(data.WHYNOTB1 == 1), 'YNB1'] = 1\n","data.loc[(data.WHYNOTB1 != 1),'YNB1'] = 0\n","\n","data['YNB2'] = \"\"\n","data.loc[(data.WHYNOTB2 == 1), 'YNB2'] = 1\n","data.loc[(data.WHYNOTB2 != 1),'YNB2'] = 0\n","\n","data['YNB3'] = \"\"\n","data.loc[(data.WHYNOTB3 == 1), 'YNB3'] = 1\n","data.loc[(data.WHYNOTB3 != 1),'YNB3'] = 0\n","\n","data['YNB4'] = \"\"\n","data.loc[(data.WHYNOTB4 == 1), 'YNB4'] = 1\n","data.loc[(data.WHYNOTB4 != 1),'YNB4'] = 0\n","\n","data['YNB5'] = \"\"\n","data.loc[(data.WHYNOTB5 == 1), 'YNB5'] = 1\n","data.loc[(data.WHYNOTB5 != 1),'YNB5'] = 0\n","\n","data['YNB6'] = \"\"\n","data.loc[(data.WHYNOTB6 == 1), 'YNB6'] = 1\n","data.loc[(data.WHYNOTB6 != 1),'YNB6'] = 0\n","\n","# We next saved the responses for these columns into a column list that we would later add to our final dataframe.\n","why_cols = [ f'YN{num}' for num in range(1,12)] + [f'YNB{num}' for num in range(1,7)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BlzuRWK6n5lb"},"source":["# After extracting and transforming our variables of interest from our combined Dataframe, our team now combined the columns that we had transformed into \n","# a single large dataframe for further analysis. This dataframe is 'fdata'. \n","\n","md_cols = [col['col_name'] for col in variables]\n","cols_keep = ['WEEK'] + subgroupList + why_cols+ md_cols \n","fdata = data[cols_keep]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":762},"id":"3sCMHSmGvKOA","executionInfo":{"status":"ok","timestamp":1618883699030,"user_tz":240,"elapsed":120972,"user":{"displayName":"Niaoniao Ma","photoUrl":"","userId":"15369324244233398216"}},"outputId":"58521d66-4a1e-4239-edae-5467f3ced956"},"source":["# Show a preview of this dataframe to ensure that it looks correct. \n","fdata"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>WEEK</th>\n","      <th>AGE_GROUP</th>\n","      <th>GENDER</th>\n","      <th>RACE_ETHNICITY</th>\n","      <th>EDUCATION</th>\n","      <th>MARITAL_STATUS</th>\n","      <th>HOUSEHOLD_SIZE</th>\n","      <th>RECVDVACC</th>\n","      <th>GETVACC</th>\n","      <th>YN1</th>\n","      <th>YN2</th>\n","      <th>YN3</th>\n","      <th>YN4</th>\n","      <th>YN5</th>\n","      <th>YN6</th>\n","      <th>YN7</th>\n","      <th>YN8</th>\n","      <th>YN9</th>\n","      <th>YN10</th>\n","      <th>YN11</th>\n","      <th>YNB1</th>\n","      <th>YNB2</th>\n","      <th>YNB3</th>\n","      <th>YNB4</th>\n","      <th>YNB5</th>\n","      <th>YNB6</th>\n","      <th>DATE</th>\n","      <th>VACC</th>\n","      <th>HADCOVID</th>\n","      <th>WRKLOSS</th>\n","      <th>KINDWORK</th>\n","      <th>TW_START</th>\n","      <th>EXPNS_DIF</th>\n","      <th>PLNDTRIPS</th>\n","      <th>ANXIOUS</th>\n","      <th>WORRY</th>\n","      <th>INTEREST</th>\n","      <th>DOWN</th>\n","      <th>PRESCRIPT</th>\n","      <th>MH_SVCS</th>\n","      <th>MH_NOTGET</th>\n","      <th>INCOME</th>\n","      <th>EST_ST</th>\n","      <th>PRIVHLTH</th>\n","      <th>PUBHLTH</th>\n","      <th>REGION</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>25 - 39</td>\n","      <td>Female</td>\n","      <td>White alone</td>\n","      <td>Bachelor's degree or higher</td>\n","      <td>Married</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2020-04-23</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>No</td>\n","      <td>Private Company</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>Nearly Every Day</td>\n","      <td>More than Half the Days</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>$50,000-74,999</td>\n","      <td>Tennessee</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>65 and above</td>\n","      <td>Male</td>\n","      <td>White alone</td>\n","      <td>Some college/associate's degree</td>\n","      <td>Others</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2020-04-23</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>No</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>More than Half the Days</td>\n","      <td>Nearly Every Day</td>\n","      <td>Nearly Every Day</td>\n","      <td>Nearly Every Day</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>$25,000-$49,999</td>\n","      <td>Alabama</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>40 - 54</td>\n","      <td>Female</td>\n","      <td>Other races</td>\n","      <td>Bachelor's degree or higher</td>\n","      <td>Married</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2020-04-23</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>No</td>\n","      <td>Non Profit Organization</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>$150,000 and above</td>\n","      <td>Michigan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>55 - 64</td>\n","      <td>Male</td>\n","      <td>White alone</td>\n","      <td>Some college/associate's degree</td>\n","      <td>Others</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2020-04-23</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>Yes</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>Nearly Every Day</td>\n","      <td>Nearly Every Day</td>\n","      <td>Nearly Every Day</td>\n","      <td>Nearly Every Day</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>Less than $25,000</td>\n","      <td>Alabama</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>55 - 64</td>\n","      <td>Female</td>\n","      <td>White alone</td>\n","      <td>Bachelor's degree or higher</td>\n","      <td>Others</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2020-04-23</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>No</td>\n","      <td>Non Profit Organization</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>Several Days</td>\n","      <td>Not at all</td>\n","      <td>Several Days</td>\n","      <td>Several Days</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>$50,000-74,999</td>\n","      <td>Alabama</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2323332</th>\n","      <td>27</td>\n","      <td>40 - 54</td>\n","      <td>Female</td>\n","      <td>White alone</td>\n","      <td>Bachelor's degree or higher</td>\n","      <td>Married</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2021-03-17</td>\n","      <td>Definitely NOT</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Government</td>\n","      <td>No Change</td>\n","      <td>Very Difficult</td>\n","      <td>Yes</td>\n","      <td>Nearly Every Day</td>\n","      <td>Nearly Every Day</td>\n","      <td>Nearly Every Day</td>\n","      <td>Nearly Every Day</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>$75,000-$99,000</td>\n","      <td>Wyoming</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>West</td>\n","    </tr>\n","    <tr>\n","      <th>2323333</th>\n","      <td>27</td>\n","      <td>40 - 54</td>\n","      <td>Female</td>\n","      <td>White alone</td>\n","      <td>Some college/associate's degree</td>\n","      <td>Married</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>-88.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2021-03-17</td>\n","      <td>Vaccinated</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Government</td>\n","      <td>No</td>\n","      <td>Somewhat Difficult</td>\n","      <td>Yes</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>Wyoming</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>West</td>\n","    </tr>\n","    <tr>\n","      <th>2323334</th>\n","      <td>27</td>\n","      <td>65 and above</td>\n","      <td>Male</td>\n","      <td>Hispanic</td>\n","      <td>Bachelor's degree or higher</td>\n","      <td>Married</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>-88.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2021-03-17</td>\n","      <td>Vaccinated</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Private Company</td>\n","      <td>Yes</td>\n","      <td>Not at all Difficult</td>\n","      <td>Yes</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>$100,000-$149,999</td>\n","      <td>Wyoming</td>\n","      <td>no</td>\n","      <td>yes</td>\n","      <td>West</td>\n","    </tr>\n","    <tr>\n","      <th>2323335</th>\n","      <td>27</td>\n","      <td>55 - 64</td>\n","      <td>Male</td>\n","      <td>White alone</td>\n","      <td>Some college/associate's degree</td>\n","      <td>Married</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>-88.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2021-03-17</td>\n","      <td>Vaccinated</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>nan</td>\n","      <td>No</td>\n","      <td>Not at all Difficult</td>\n","      <td>Yes</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>$50,000-74,999</td>\n","      <td>Wyoming</td>\n","      <td>yes</td>\n","      <td>yes</td>\n","      <td>West</td>\n","    </tr>\n","    <tr>\n","      <th>2323336</th>\n","      <td>27</td>\n","      <td>55 - 64</td>\n","      <td>Female</td>\n","      <td>White alone</td>\n","      <td>Some college/associate's degree</td>\n","      <td>Married</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2021-03-17</td>\n","      <td>Probably</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>nan</td>\n","      <td>nan</td>\n","      <td>Not at all Difficult</td>\n","      <td>No</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>$25,000-$49,999</td>\n","      <td>Wyoming</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>West</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2323337 rows Ã— 46 columns</p>\n","</div>"],"text/plain":["         WEEK     AGE_GROUP  GENDER  ... PRIVHLTH PUBHLTH REGION\n","0           1       25 - 39  Female  ...      nan     nan    nan\n","1           1  65 and above    Male  ...      nan     nan    nan\n","2           1       40 - 54  Female  ...      nan     nan    nan\n","3           1       55 - 64    Male  ...      nan     nan    nan\n","4           1       55 - 64  Female  ...      nan     nan    nan\n","...       ...           ...     ...  ...      ...     ...    ...\n","2323332    27       40 - 54  Female  ...      yes      no   West\n","2323333    27       40 - 54  Female  ...      nan     nan   West\n","2323334    27  65 and above    Male  ...       no     yes   West\n","2323335    27       55 - 64    Male  ...      yes     yes   West\n","2323336    27       55 - 64  Female  ...      yes      no   West\n","\n","[2323337 rows x 46 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"GOpfi1K-qJvt"},"source":["# Lastly, now that our final Dataframe is ready, our team saved this dataframe into a Parquet file that we could export to visualization software.\n","\n","# File path that this parquet file was saved to was removed to maintain anonymity.\n","fdata.to_parquet('')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JFfrB7XRqZvt"},"source":["# We also opted to save our final dataframe into a CSV file for use on external visualization software in our Shared Drive.\n","\n","# File path that this CSV file was saved to was removed to maintain anonymity.\n","fdata.to_csv('')"],"execution_count":null,"outputs":[]}]}